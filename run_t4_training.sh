#!/bin/bash

# é’ˆå¯¹4ä¸ªT4 GPUçš„å®Œæ•´è®­ç»ƒæµç¨‹è„šæœ¬
# åŸºäºrun1000.shä¿®æ”¹ï¼Œä¸“é—¨ä¸ºT4 GPUçš„16GBæ˜¾å­˜é™åˆ¶è¿›è¡Œä¼˜åŒ–

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

echo "ğŸš€ å¼€å§‹T4 GPUè®­ç»ƒæµç¨‹..."

# ç¯å¢ƒè®¾ç½®
export OMP_NUM_THREADS=1
export NANOCHAT_BASE_DIR=".cache/nanochat"
export DATA_DIR="./data"
mkdir -p $NANOCHAT_BASE_DIR
mkdir -p $DATA_DIR

# æ£€æŸ¥å¹¶å®‰è£…uv
command -v uv &> /dev/null || curl -LsSf https://astral.sh/uv/install.sh | sh

# è®¾ç½®è™šæ‹Ÿç¯å¢ƒ
[ -d ".venv" ] || uv venv
uv sync --extra gpu
source .venv/bin/activate

# è®¾ç½®wandbè¿è¡Œåç§°
if [ -z "$WANDB_RUN" ]; then
    WANDB_RUN="t4_training_$(date +%Y%m%d_%H%M%S)"
fi
echo "ğŸ“Š Wandbè¿è¡Œåç§°: $WANDB_RUN"

# é‡ç½®æŠ¥å‘Š
python -m nanochat.report reset

# å®‰è£…Rustå’Œç¼–è¯‘tokenizer
echo "ğŸ”§ ç¼–è¯‘ Rust tokenizer..."
if [ ! -d "$HOME/.cargo" ]; then
    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
fi
source "$HOME/.cargo/env"
uv run maturin develop --release --manifest-path rustbpe/Cargo.toml

echo "ğŸ“Š å¼€å§‹æ•°æ®å‡†å¤‡..."
echo "=================================================="

# æ­¥éª¤1: ä¸‹è½½å¹¶éªŒè¯æ‰€æœ‰æ•°æ®
echo "ğŸ“¥ ä¸‹è½½è®­ç»ƒå’Œè¯„ä¼°æ•°æ®..."
python -m scripts.prepare_data --data-dir $DATA_DIR --num-base-shards 100 --num-workers 4

# æ­¥éª¤2: éªŒè¯æ•°æ®å®Œæ•´æ€§
echo ""
echo "ğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§..."
python -m nanochat.data_checker
if [ $? -ne 0 ]; then
    echo "âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥ï¼è¯·æ£€æŸ¥æ•°æ®ä¸‹è½½ã€‚"
    exit 1
fi

echo ""
echo "âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼"
echo "=================================================="
echo ""

# è®­ç»ƒtokenizer
echo "ğŸ”¤ è®­ç»ƒtokenizer..."
python -m scripts.tok_train --max_chars=2000000000  # å‡å°‘å­—ç¬¦æ•°ä»¥é€‚åº”T4
python -m scripts.tok_eval

echo "ğŸ‹ï¸ å¼€å§‹åŸºç¡€æ¨¡å‹è®­ç»ƒ..."

# åŸºç¡€æ¨¡å‹è®­ç»ƒ - é’ˆå¯¹T4ä¼˜åŒ–
echo "ğŸ“ˆ è¿è¡ŒåŸºç¡€è®­ç»ƒ (æ·±åº¦12, æ‰¹æ¬¡å¤§å°4)..."
torchrun --standalone --nproc_per_node=4 -m scripts.t4_train -- --run=$WANDB_RUN

echo "ğŸ“Š è¿è¡ŒåŸºç¡€æŸå¤±è¯„ä¼°..."
torchrun --standalone --nproc_per_node=4 -m scripts.base_loss

echo "ğŸ“Š è¿è¡ŒåŸºç¡€æ¨¡å‹è¯„ä¼°..."
torchrun --standalone --nproc_per_node=4 -m scripts.base_eval

echo "ğŸ¯ å¼€å§‹ä¸­æœŸè®­ç»ƒ..."

# ä¸­æœŸè®­ç»ƒ - é’ˆå¯¹T4ä¼˜åŒ–
echo "ğŸ“ˆ è¿è¡Œä¸­æœŸè®­ç»ƒ (æ‰¹æ¬¡å¤§å°2)..."
torchrun --standalone --nproc_per_node=4 -m scripts.t4_mid_train -- --run=$WANDB_RUN

echo "ğŸ“Š è¿è¡Œä¸­æœŸè®­ç»ƒè¯„ä¼°..."
torchrun --standalone --nproc_per_node=4 -m scripts.chat_eval -- -i mid

echo "ğŸ’¬ å¼€å§‹SFTè®­ç»ƒ..."

# SFTè®­ç»ƒ - é’ˆå¯¹T4ä¼˜åŒ–
echo "ğŸ“ˆ è¿è¡ŒSFTè®­ç»ƒ (æ‰¹æ¬¡å¤§å°1)..."
torchrun --standalone --nproc_per_node=4 -m scripts.t4_chat_sft -- --run=$WANDB_RUN

echo "ğŸ“Š è¿è¡ŒSFTè¯„ä¼°..."
torchrun --standalone --nproc_per_node=4 -m scripts.chat_eval -- -i sft

echo "ğŸ“‹ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š..."
python -m nanochat.report generate

echo "ğŸ‰ T4è®­ç»ƒæµç¨‹å®Œæˆï¼"
echo "ğŸ“Š æŸ¥çœ‹æŠ¥å‘Š: python -m nanochat.report show"
echo "ğŸ’¬ å¯åŠ¨èŠå¤©ç•Œé¢: python -m scripts.chat_web"

# æ˜¾ç¤ºGPUä½¿ç”¨æƒ…å†µ
echo "ğŸ” å½“å‰GPUçŠ¶æ€:"
nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits

echo "âœ… æ‰€æœ‰è®­ç»ƒæ­¥éª¤å·²å®Œæˆï¼"
